{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script plot the qualitatives figures with BB around GT and results\n",
    "# It includes the results for DISCount as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weight from /media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Striga_Strategy1//output/R_50_C4_1x_pre_19/model_bestval.pth.\n",
      "['__background__', 'Germinated', 'Non-germinated']\n",
      "Loading weight from /media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Striga_Strategy2//output/R_50_C4_1x_pre_20/model_bestval.pth.\n",
      "['__background__', 'Radicle', 'Seed']\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from demo.predictor import COCODemo\n",
    "from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.data.datasets import FolderDataset\n",
    "from maskrcnn_benchmark.engine.inference import inference\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.utils.collect_env import collect_env_info\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from maskrcnn_benchmark.utils.logger import setup_logger\n",
    "from maskrcnn_benchmark.utils.miscellaneous import mkdir\n",
    "from maskrcnn_benchmark.utils.imports import import_file\n",
    "\n",
    "# from predictor import Cococompute_prediction, select_top_predictions, Resize\n",
    "# Check if we can enable mixed-precision via apex.amp\n",
    "try:\n",
    "    from apex import amp\n",
    "except ImportError:\n",
    "    raise ImportError('Use APEX for mixed precision via apex.amp')\n",
    "\n",
    "\n",
    "model = \"R_50_C4_1x\"\n",
    "run = 19\n",
    "Results = {}\n",
    "\n",
    "config_file = f\"configs/e2e_faster_rcnn_{model}.yaml\" # args.config_file #\"../configs/caffe2/e2e_mask_rcnn_R_50_FPN_1x_caffe2.yaml\"\n",
    "\n",
    "model = \"R_50_C4_1x_pre\"\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n",
    "#     cfg.merge_from_list(args.opts)\n",
    "\n",
    "# cfg.DATASETS.DATA_DIR = data\n",
    "cfg.TEST.IMS_PER_BATCH = 1 \n",
    "cfg.TEST.DETECTIONS_PER_IMG = 200 \n",
    "cfg.MODEL.ROI_HEADS.DETECTIONS_PER_IMG = 200 \n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_CLASSES = 3 \n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 3 \n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NMS = 0.1\n",
    "# print(cfg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "data = f\"/media/giancos/Football/CloudLabeling/Seeds_Striga_Strategy1/\"\n",
    "weight = f\"/media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Striga_Strategy1/\"\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.5,\n",
    "    weight_loading=f\"{weight}/output/{model}_{run}/model_bestval.pth\"\n",
    ")\n",
    "\n",
    "dataset = FolderDataset(data, \"Testing\")\n",
    "COCODemo.CATEGORIES = dataset.CLASSES\n",
    "\n",
    "image, target, index = dataset[9]\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "predictions = coco_demo.compute_prediction(image)\n",
    "\n",
    "Results.update({f\"Pred_G\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"Pred_NG\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "Results.update({f\"GT_G\": target[torch.nonzero(target.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"GT_NG\": target[torch.nonzero(target.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "data = f\"/media/giancos/Football/CloudLabeling/Seeds_Striga_Strategy2/\"\n",
    "weight = f\"/media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Striga_Strategy2/\"\n",
    "run = 20\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.5,\n",
    "    weight_loading=f\"{weight}/output/{model}_{run}/model_bestval.pth\"\n",
    ")\n",
    "\n",
    "dataset = FolderDataset(data, \"Testing\")\n",
    "COCODemo.CATEGORIES = dataset.CLASSES\n",
    "\n",
    "image, target, index = dataset[9]\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "predictions = coco_demo.compute_prediction(image)\n",
    "\n",
    "Results.update({f\"Pred_R\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"Pred_S\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "Results.update({f\"GT_R\": target[torch.nonzero(target.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"GT_S\": target[torch.nonzero(target.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxList(num_boxes=104, image_width=2592, image_height=1944, mode=xyxy)\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pred_G': BoxList(num_boxes=41, image_width=2592, image_height=1944, mode=xyxy), 'Pred_NG': BoxList(num_boxes=32, image_width=2592, image_height=1944, mode=xyxy), 'GT_G': BoxList(num_boxes=44, image_width=2592, image_height=1944, mode=xyxy), 'GT_NG': BoxList(num_boxes=36, image_width=2592, image_height=1944, mode=xyxy), 'Pred_R': BoxList(num_boxes=50, image_width=2592, image_height=1944, mode=xyxy), 'Pred_S': BoxList(num_boxes=54, image_width=2592, image_height=1944, mode=xyxy), 'GT_R': BoxList(num_boxes=44, image_width=2592, image_height=1944, mode=xyxy), 'GT_S': BoxList(num_boxes=80, image_width=2592, image_height=1944, mode=xyxy)}\n"
     ]
    }
   ],
   "source": [
    "print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image139.jpg\n",
      "(1944, 2592, 3)\n",
      "['GT_G', 'Pred_G']\n",
      "(1944, 2592, 3)\n",
      "['GT_NG', 'Pred_NG']\n",
      "(1944, 2592, 3)\n",
      "['GT_R', 'Pred_R']\n",
      "(1944, 2592, 3)\n",
      "['GT_S', 'Pred_S']\n",
      "(1944, 2592, 3)\n",
      "['Pred_R', 'Pred_S']\n",
      "(1944, 2592, 3)\n",
      "['Pred_G', 'Pred_NG']\n",
      "(1944, 2592, 3)\n",
      "['GT_R', 'GT_S']\n",
      "(1944, 2592, 3)\n",
      "['GT_G', 'GT_NG']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_name = dataset.img_files[index].split(\"/\")[-1]\n",
    "print(image_name)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "def drawline(img,pt1,pt2,color,thickness=1,style='dotted',gap=20):\n",
    "    dist =((pt1[0]-pt2[0])**2+(pt1[1]-pt2[1])**2)**.5\n",
    "    pts= []\n",
    "    for i in  np.arange(0,dist,gap):\n",
    "        r=i/dist\n",
    "        x=int((pt1[0]*(1-r)+pt2[0]*r)+.5)\n",
    "        y=int((pt1[1]*(1-r)+pt2[1]*r)+.5)\n",
    "        p = (x,y)\n",
    "        pts.append(p)\n",
    "\n",
    "    if style=='dotted':\n",
    "        for p in pts:\n",
    "            cv2.circle(img,p,thickness,color,-1)\n",
    "    else:\n",
    "        s=pts[0]\n",
    "        e=pts[0]\n",
    "        i=0\n",
    "        for p in pts:\n",
    "            s=e\n",
    "            e=p\n",
    "            if i%2==1:\n",
    "                cv2.line(img,s,e,color,thickness)\n",
    "            i+=1\n",
    "\n",
    "def drawpoly(img,pts,color,thickness=1,style='dotted',):\n",
    "    s=pts[0]\n",
    "    e=pts[0]\n",
    "    pts.append(pts.pop(0))\n",
    "    for p in pts:\n",
    "        s=e\n",
    "        e=p\n",
    "        drawline(img,s,e,color,thickness,style)\n",
    "\n",
    "def drawrect(img,pt1,pt2,color,thickness=1,style='dotted'):\n",
    "    pts = [pt1,(pt2[0],pt1[1]),pt2,(pt1[0],pt2[1])] \n",
    "    drawpoly(img,pts,color,thickness,style)\n",
    "\n",
    "\n",
    "def createQualitative(image,keys, out, GT_only=False,\n",
    "                      folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\"):\n",
    "    result = image.copy()\n",
    "    print(result.shape)\n",
    "    print(keys)\n",
    "    for key in keys:\n",
    "    #     key = keys[1]\n",
    "        # print(key)\n",
    "        labels = Results[key].get_field(\"labels\").tolist()\n",
    "        boxes = Results[key].bbox\n",
    "\n",
    "        color=[0.5]*3\n",
    "        if \"_G\" in key: color=[17, 172, 222]\n",
    "        if \"_NG\" in key: color=[32, 36, 143]\n",
    "        if \"_S\" in key: color=[234, 140, 95]\n",
    "        if \"_R\" in key: color=[134, 7, 3]\n",
    "#         if \"DC_S\" in key: color=[int(0.6*234), int(0.6*140), int(0.6*95)]\n",
    "#         if \"DC_R\" in key: color=[int(0.6*134), int(0.6*7), int(0.6*3)]\n",
    "        if \"GT_\" in key and not GT_only: color=[0,0,0]\n",
    "\n",
    "\n",
    "        for i_label, box in zip(labels, boxes):\n",
    "            box = box.to(torch.int64)\n",
    "            top_left, bottom_right = box[:2].tolist(), box[2:].tolist()\n",
    "            if \"GT_\" in key or \"DC_\" in key:\n",
    "                result = cv2.rectangle(\n",
    "                    result, tuple(top_left), tuple(bottom_right), tuple(color), 5\n",
    "                )\n",
    "            else:\n",
    "                drawrect(result,tuple(top_left), tuple(bottom_right), tuple(color), 5, style=\"dotted\")\n",
    "\n",
    "#     print(result)\n",
    "\n",
    "    result = Image.fromarray(result)\n",
    "    \n",
    "    # out = \"_\".join(keys) + \".jpg\" #\"Strat1.jpg\"\n",
    "    result.save(folder+out)\n",
    "    \n",
    "createQualitative(image, [\"GT_G\",\"Pred_G\"], \"G_GT_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"GT_NG\",\"Pred_NG\"], \"NG_GT_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"GT_R\",\"Pred_R\"], \"R_GT_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"GT_S\",\"Pred_S\"], \"S_GT_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "\n",
    "\n",
    "createQualitative(image, [\"Pred_R\",\"Pred_S\"], \"Pred_R_S.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"Pred_G\",\"Pred_NG\"], \"Pred_NG_G.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"GT_R\",\"GT_S\"], \"GT_R_S.jpg\",GT_only=True,\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"GT_G\",\"GT_NG\"], \"GT_NG_G.jpg\",GT_only=True,\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxList(num_boxes=82, image_width=2592, image_height=1944, mode=xyxy)\n",
      "(1944, 2592, 3)\n",
      "['Pred_DC_R', 'Pred_R']\n",
      "(1944, 2592, 3)\n",
      "['Pred_DC_S', 'Pred_S']\n",
      "(1944, 2592, 3)\n",
      "['Pred_DC_S', 'Pred_DC_R']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "\n",
    "preds_discord = []\n",
    "for img in dataset.img_files:\n",
    "#     print(img)\n",
    "    discount_pred_file = os.path.basename(img).replace(\".jpg\",\".txt\")\n",
    "    discount_pred_file = os.path.join(\"/media/giancos/Football/CloudLabeling_DS/Discount_Striga\",discount_pred_file)\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    with open(discount_pred_file,\"r\") as file:\n",
    "        \n",
    "        data = file.read()\n",
    "        lines = data.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            line = line.split(\",\")\n",
    "            if len(line) < 4:\n",
    "                break\n",
    "            boxes.append([float(line[0]),float(line[1]),float(line[2]),float(line[3])])\n",
    "            if int(float(line[5])) == 0:\n",
    "                labels.append(2)\n",
    "            elif int(float(line[5])) == 1:\n",
    "                labels.append(1)\n",
    "            scores.append(float(line[4]))\n",
    "#         print()\n",
    "#     print(boxes)\n",
    "    boxlist = BoxList(boxes, (2592, 1944), mode=\"xyxy\")\n",
    "    boxlist.add_field(\"labels\", torch.tensor(labels))\n",
    "    boxlist.add_field(\"scores\", torch.tensor(scores))\n",
    "#     boxlist = boxlist.resize((1066, 800))\n",
    "#     print(boxlist)\n",
    "    preds_discord.append(boxlist)\n",
    "print(preds_discord[0])\n",
    "pred_discord = preds_discord[9]\n",
    "Results.update({f\"Pred_DC_R\": pred_discord[torch.nonzero(pred_discord.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"Pred_DC_S\": pred_discord[torch.nonzero(pred_discord.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "\n",
    "        \n",
    "createQualitative(image, [\"Pred_DC_R\",\"Pred_R\"], \"R_DC_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"Pred_DC_S\",\"Pred_S\"], \"S_DC_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "createQualitative(image, [\"Pred_DC_S\",\"Pred_DC_R\"], \"DC_Pred.jpg\",\n",
    "                 folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/StrigaDotted/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OROBANCHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weight from /media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Orobanche_Strategy1_finetuning_201030//output/R_50_FPN_1x_pre_20/model_bestval.pth.\n",
      "['__background__', 'Germinated', 'Non-germinated']\n",
      "Loading weight from /media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Orobanche_Strategy2_finetuning_201030//output/R_50_FPN_1x_pre_20/model_bestval.pth.\n",
      "['__background__', 'Radicle', 'Seed']\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from demo.predictor import COCODemo\n",
    "from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.data.datasets import FolderDataset\n",
    "from maskrcnn_benchmark.engine.inference import inference\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.utils.collect_env import collect_env_info\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from maskrcnn_benchmark.utils.logger import setup_logger\n",
    "from maskrcnn_benchmark.utils.miscellaneous import mkdir\n",
    "from maskrcnn_benchmark.utils.imports import import_file\n",
    "\n",
    "# from predictor import Cococompute_prediction, select_top_predictions, Resize\n",
    "# Check if we can enable mixed-precision via apex.amp\n",
    "try:\n",
    "    from apex import amp\n",
    "except ImportError:\n",
    "    raise ImportError('Use APEX for mixed precision via apex.amp')\n",
    "\n",
    "\n",
    "model = \"R_50_FPN_1x\"\n",
    "run = 20\n",
    "Results = {}\n",
    "\n",
    "config_file = f\"configs/e2e_faster_rcnn_{model}.yaml\" # args.config_file #\"../configs/caffe2/e2e_mask_rcnn_R_50_FPN_1x_caffe2.yaml\"\n",
    "\n",
    "model = \"R_50_FPN_1x_pre\"\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n",
    "#     cfg.merge_from_list(args.opts)\n",
    "\n",
    "# cfg.DATASETS.DATA_DIR = data\n",
    "cfg.TEST.IMS_PER_BATCH = 1 \n",
    "cfg.TEST.DETECTIONS_PER_IMG = 200 \n",
    "cfg.MODEL.ROI_HEADS.DETECTIONS_PER_IMG = 200 \n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_CLASSES = 3 \n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 3 \n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NMS = 0.1\n",
    "# print(cfg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "data = f\"/media/giancos/Football/CloudLabeling/Seeds_Orobanche_Strategy1_finetuning_201030/\"\n",
    "weight = f\"/media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Orobanche_Strategy1_finetuning_201030/\"\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.5,\n",
    "    weight_loading=f\"{weight}/output/{model}_{run}/model_bestval.pth\"\n",
    ")\n",
    "\n",
    "dataset = FolderDataset(data, \"Testing\")\n",
    "COCODemo.CATEGORIES = dataset.CLASSES\n",
    "\n",
    "image, target, index = dataset[9]\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "predictions = coco_demo.compute_prediction(image)\n",
    "\n",
    "Results.update({f\"Pred_G\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"Pred_NG\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "Results.update({f\"GT_G\": target[torch.nonzero(target.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"GT_NG\": target[torch.nonzero(target.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "data = f\"/media/giancos/Football/CloudLabeling/Seeds_Orobanche_Strategy2_finetuning_201030/\"\n",
    "weight = f\"/media/giancos/Football/CloudLabeling_DS/CloudLabeling/Seeds_Orobanche_Strategy2_finetuning_201030/\"\n",
    "run = 20\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.5,\n",
    "    weight_loading=f\"{weight}/output/{model}_{run}/model_bestval.pth\"\n",
    ")\n",
    "\n",
    "dataset = FolderDataset(data, \"Testing\")\n",
    "COCODemo.CATEGORIES = dataset.CLASSES\n",
    "\n",
    "image, target, index = dataset[9]\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "predictions = coco_demo.compute_prediction(image)\n",
    "\n",
    "Results.update({f\"Pred_R\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"Pred_S\": predictions[torch.nonzero(predictions.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "Results.update({f\"GT_R\": target[torch.nonzero(target.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"GT_S\": target[torch.nonzero(target.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image060.jpg\n",
      "(1944, 2592, 3)\n",
      "['GT_G', 'Pred_G']\n",
      "(1944, 2592, 3)\n",
      "['GT_NG', 'Pred_NG']\n",
      "(1944, 2592, 3)\n",
      "['GT_R', 'Pred_R']\n",
      "(1944, 2592, 3)\n",
      "['GT_S', 'Pred_S']\n",
      "(1944, 2592, 3)\n",
      "['Pred_R', 'Pred_S']\n",
      "(1944, 2592, 3)\n",
      "['Pred_G', 'Pred_NG']\n",
      "(1944, 2592, 3)\n",
      "['GT_R', 'GT_S']\n",
      "(1944, 2592, 3)\n",
      "['GT_G', 'GT_NG']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_name = dataset.img_files[index].split(\"/\")[-1]\n",
    "print(image_name)\n",
    "\n",
    "\n",
    "    \n",
    "createQualitative(image, [\"GT_G\",\"Pred_G\"], \"G_GT_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"GT_NG\",\"Pred_NG\"], \"NG_GT_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"GT_R\",\"Pred_R\"], \"R_GT_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"GT_S\",\"Pred_S\"], \"S_GT_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "\n",
    "\n",
    "createQualitative(image, [\"Pred_R\",\"Pred_S\"], \"Pred_R_S.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"Pred_G\",\"Pred_NG\"], \"Pred_NG_G.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"GT_R\",\"GT_S\"], \"GT_R_S.jpg\",GT_only=True,\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"GT_G\",\"GT_NG\"], \"GT_NG_G.jpg\",GT_only=True,\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxList(num_boxes=52, image_width=2592, image_height=1944, mode=xyxy)\n",
      "(1944, 2592, 3)\n",
      "['Pred_DC_R', 'Pred_R']\n",
      "(1944, 2592, 3)\n",
      "['Pred_DC_S', 'Pred_S']\n",
      "(1944, 2592, 3)\n",
      "['Pred_DC_S', 'Pred_DC_R']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "\n",
    "preds_discord = []\n",
    "for img in dataset.img_files:\n",
    "#     print(img)\n",
    "    discount_pred_file = os.path.basename(img).replace(\".jpg\",\".txt\")\n",
    "    discount_pred_file = os.path.join(\"/media/giancos/Football/CloudLabeling_DS/Discount_Orobanche\",discount_pred_file)\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    with open(discount_pred_file,\"r\") as file:\n",
    "        \n",
    "        data = file.read()\n",
    "        lines = data.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            line = line.split(\",\")\n",
    "            if len(line) < 4:\n",
    "                break\n",
    "            boxes.append([float(line[0]),float(line[1]),float(line[2]),float(line[3])])\n",
    "            if int(float(line[5])) == 0:\n",
    "                labels.append(2)\n",
    "            elif int(float(line[5])) == 1:\n",
    "                labels.append(1)\n",
    "            scores.append(float(line[4]))\n",
    "#         print()\n",
    "#     print(boxes)\n",
    "    boxlist = BoxList(boxes, (2592, 1944), mode=\"xyxy\")\n",
    "    boxlist.add_field(\"labels\", torch.tensor(labels))\n",
    "    boxlist.add_field(\"scores\", torch.tensor(scores))\n",
    "#     boxlist = boxlist.resize((1066, 800))\n",
    "#     print(boxlist)\n",
    "    preds_discord.append(boxlist)\n",
    "print(preds_discord[0])\n",
    "pred_discord = preds_discord[9]\n",
    "Results.update({f\"Pred_DC_R\": pred_discord[torch.nonzero(pred_discord.get_field(\"labels\") == 1).squeeze(1)]})\n",
    "Results.update({f\"Pred_DC_S\": pred_discord[torch.nonzero(pred_discord.get_field(\"labels\") == 2).squeeze(1)]})\n",
    "\n",
    "        \n",
    "createQualitative(image, [\"Pred_DC_R\",\"Pred_R\"], \"R_DC_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"Pred_DC_S\",\"Pred_S\"], \"S_DC_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "createQualitative(image, [\"Pred_DC_S\",\"Pred_DC_R\"], \"DC_Pred.jpg\",\n",
    "                  folder=f\"/home/giancos/Dropbox/Applicazioni/ShareLaTeX/SeedsResults/Qualitative/OrobancheDotted/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:maskrcnn_benchmark]",
   "language": "python",
   "name": "conda-env-maskrcnn_benchmark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
